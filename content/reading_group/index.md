---
title: Reading Group
summary: Papers and program of the MilaNLP Reading Group
date: "2018-06-28T00:00:00Z"

reading_time: false  # Show estimated reading time?
share: false  # Show social sharing links?
profile: false  # Show author profile?
comments: false  # Show comments?

# Optional header image (relative to `assets/media/` folder).
header:
  caption: ""
  image: ""
---

The Reading Group is our weekly meeting to present and discuss exciting contributions from the community.

It currently takes place every Thursday at 12:00 PM (Milan). For more info, feel free to [reach out](mailto:donya.rooein@unibocconi.it).

## Upcoming Program

| Date | Presenter | Paper |
| ---- | ----------- | ---- | 
| Jun-11	| paul | [Evaluating the persuasive influence of political microtargeting with large language models](https://www.pnas.org/doi/10.1073/pnas.2403116121) |




See below for past talks.

<!-- - Sep-14, Giuseppe, [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants](https://arxiv.org/abs/2308.16884)
- Sep-21, Karina, [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://aclanthology.org/2020.emnlp-main.154.pdf)
- Sep-28, Debora, [Do Multilingual Language Models Think Better in English?](https://arxiv.org/abs/2308.01223)
- Oct-5, Amanda, [Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems](https://dl.acm.org/doi/10.1145/3544548.3581025)
- Oct-12, Kai, [Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings](https://aclanthology.org/N19-1304.pdf)
- Oct-19, Dirk, [Can AI-Generated Text be Reliably Detected?](https://arxiv.org/pdf/2303.11156.pdf)
- Oct-26, Lorenzo
- Nov-2,
- Nov-9
- Nov-16, Donya	
- Nov-23, Paul	
- Nov-30, Flor	
- Dec-7, *break (EMNLP)*
- Dec-14 
- Dec-21
- Dec-28, *break (Christmas)* -->

![An AI generated image of two kittens looking at a pile of papers](https://storage.googleapis.com/pai-images/4052a8b4bb134ffb953b417e3a03da6e.jpeg)

## Past Talks

| Date      | Presenter | Paper |
| ----------- | ----------- | ---- |
| Sep 14 | Giuseppe | [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants](https://arxiv.org/abs/2308.16884) |
| Sep 21 | Karina | [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://aclanthology.org/2020.emnlp-main.154.pdf)
| Sep 21 | Debora | [Do Multilingual Language Models Think Better in English?](https://arxiv.org/abs/2308.01223) |
| Oct 5 | Amanda | [Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems](https://dl.acm.org/doi/10.1145/3544548.3581025) |
| Oct 12 | Kai | [Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings](https://aclanthology.org/N19-1304.pdf) |
| Oct 19 | Dirk | [Can AI-Generated Text be Reliably Detected?](https://arxiv.org/pdf/2303.11156.pdf) |
| Oct 26 | Lorenzo | [The uselessness of AI ethics](https://link.springer.com/article/10.1007/s43681-022-00209-w) |
| Nov 2 | Serena | [Topic Modeling in Embedding Spaces](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00325/96463/Topic-Modeling-in-Embedding-Spaces) |
| Nov 9 | Carolin | [SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://arxiv.org/abs/2303.08896) |
| Nov 16 | Donya | [Time Travel in LLMs: Tracing Data Contamination in Large Language Models](https://arxiv.org/abs/2308.08493) |
| Nov 23 | Paul | [Towards Evaluating AI Systems for Moral Status Using Self-Reports](https://arxiv.org/abs/2311.08576) |
| Jan 18 | Flor | [Can Large Language Models Transform Computational Social Science?](https://arxiv.org/abs/2305.03514) |
| Jan 25 | Giuseppe | [Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://arxiv.org/abs/2401.06102) |
| Feb 1 | Amanda | Regulation and NLP (RegNLP): Taming Large Language Models (https://aclanthology.org/2023.emnlp-main.539/) |
| Feb 8 | Anne | [What is ‘Typological Diversity’ in NLP?](https://arxiv.org/pdf/2402.04222.pdf) |
| Feb 15 | Carolin | [Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer](https://aclanthology.org/2023.emnlp-main.854.pdf) |
| Feb 22 | Lorenzo | [Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties](https://arxiv.org/abs/2309.00779)
| Feb 29 | Paul | [A Roadmap to Pluralistic Alignment](https://arxiv.org/abs/2402.05070) |
| Mar 7 | Dirk | [The Generative AI Paradox: "What It Can Create, It May Not Understand"](https://arxiv.org/abs/2311.00059) |
| Mar 14 | Donya | [Mission: Impossible Language Models](https://arxiv.org/abs/2401.06416) |
| Mar 28 | Mikel | [Language Model Tokenizers Introduce Unfairness Between Languages](https://arxiv.org/abs/2305.15425) |
| Apr 4 | Derya | [KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models](https://arxiv.org/pdf/2310.11220.pdf) |
| Apr 11 | Emanuele | [scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1.full) |
| Apr 18 | Kai | [Improving Wikipedia verifiability with AI](https://www.nature.com/articles/s42256-023-00726-1) |
| Apr 25 | Michele | [Fairwashing: the risk of rationalization](https://arxiv.org/abs/1901.09749) |
| May-9 | Janis | [Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations](https://arxiv.org/abs/2310.07849)|
| May-19 | Amanda | [QUANTIFYING LANGUAGE MODELS’ SENSITIVITY TO SPURIOUS FEATURES IN PROMPT DESIGN or: How I learned to start worrying about prompt formatting](https://arxiv.org/pdf/2310.11324) |
